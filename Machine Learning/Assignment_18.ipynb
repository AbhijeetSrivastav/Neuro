{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. What is the difference between supervised and unsupervised learning? Give some examples to\n",
    "illustrate your point."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "\n",
    "**Supervised Learning**\n",
    "- In this type of learning we know the truth value for set of input feature instance which is called label or target column or output feature.\n",
    "- We try to find out relationship between the input features and output feature and based on this relationship which is basically a mathematical formulation we try to predict or classify the value of the output feature.\n",
    "- Ex - Classifying diabetes.\n",
    "\n",
    "**Unsupervised Learning**\n",
    "- In this type of learning we don't have any defined target or output feature.\n",
    "- We try yo group the data based on their similarity by creating the mapping function or relationship equation.\n",
    "- Ex - Will it rain or not today? \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. Mention a few unsupervised learning applications.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: Unsupervised learning applications:\n",
    "1. Customer Segmentation\n",
    "2. Movie Recomendation\n",
    "3. Product Segmentation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. What are the three main types of clustering methods? Briefly describe the characteristics of each."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: \n",
    "\n",
    "1. **Centroid Based:** It works on the closeness of the data points to the chosen central value. The datasets are divided into a given number of clusters, and a vector of values references every cluster. The input data variable is compared to the vector value and enters the cluster with minimal difference.\n",
    "\n",
    "2. **Density Based:** Density-based clustering method considers density ahead of distance. Data is clustered by regions of high concentrations of data objects bounded by areas of low concentrations of data objects. The clusters formed are grouped as a maximal set of connected data points.\n",
    "\n",
    "3. **Hierachical Based:** The clusters are represented in extensive hierarchical structures separated by a maximum distance required to connect the cluster parts. The clusters are represented as Dendrograms, where X-axis represents the objects that do not merge while Y-axis is the distance at which clusters merge. The similar data objects have minimal distance falling in the same cluster, and the dissimilar data objects are placed farther in the hierarchy."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Explain how the k-means algorithm determines the consistency of clustering."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: A random sample is divided into the k clusters that minimise the within cluster sum of squares. Conditions are found that ensure the almost sure convergence, as the sample size increases, of the set of means of the k clusters. The result is proved for a more general clustering criterion."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. With a simple illustration, explain the key difference between the k-means and k-medoids\n",
    "algorithms."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: K-means attempts to minimize the total squared error, while k-medoids minimizes the sum of dissimilarities between points labeled to be in a cluster and a point designated as the center of that cluster. In contrast to the k -means algorithm, k -medoids chooses datapoints as centers ( medoids or exemplars).\n",
    "\n",
    "![](../Assets/kk.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. What is a dendrogram, and how does it work? Explain how to do it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: Dendogram is used to represent hierarchy based clustering algorithm. The clusters are made based on simialrity or closeness.\n",
    "\n",
    "\n",
    "![](../Assets/dendo.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. What exactly is SSE? What role does it play in the k-means algorithm?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: SSE or Sum of Squared Eculedian Distance is a distance measure technique using which we measure the distance between the centroid and data points.\n",
    "\n",
    "$$ SSE = \\sqrt{((x_{2} - x_{1})^2 + (y_{2} - y_{1})^2)} $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8. With a step-by-step algorithm, explain the k-means procedure."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "\n",
    "1) Randomly k centroids.\n",
    "\n",
    "2) Calculate the distance between each data point and centroid.\n",
    "\n",
    "3) Assign the data point to the cluster whose centroid is nearest to it.\n",
    "\n",
    "4) Recalculate the centroid of the new cluster by takin mean of the new cluster data points.\n",
    "\n",
    "5) Recalculate the distance between each data point and new obtained cluster centers, if no data point was reassigned then stop, otherwise repeat from step 3). "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9. In the sense of hierarchical clustering, define the terms single link and complete link."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "\n",
    "1. **Single Linkage:** For two clusters C1 and C2, the single linkage returns the minimum distance between two points P1 and P2 such that P1 belongs to C1 and P2 belongs to C2.\n",
    "\n",
    "2. **Complete Linkage:** For two clusters C1 and C2, the complete linkage returns the maximum distance between two points P1 and P2 such that P1 belongs to C1 and P2 belongs to C2."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10. How does the apriori concept aid in the reduction of measurement overhead in a business\n",
    "basket analysis? Give an example to demonstrate your point."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: Apriori is an algorithm for frequent item set mining and association rule learning over relational databases. It proceeds by identifying the frequent individual items in the database and extending them to larger and larger item sets as long as those item sets appear sufficiently often in the database."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
